{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# De scikit-learn...\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Estandarización y modelado\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.compose import make_column_selector\n",
    "# Division de los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Normalización\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Regresiones\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso, ElasticNet, RidgeCV, ElasticNetCV, LassoCV, LogisticRegression\n",
    "\n",
    "# ML metricas\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from setuptools import setup\n",
    "from distutils.core import setup\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "import optuna\n",
    "from optuna.trial import Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>RainfallTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity3pm  Pressure9am  \\\n",
       "0           W           44.0          W  ...        22.0       1007.7   \n",
       "1         WNW           44.0        NNW  ...        25.0       1010.6   \n",
       "2         WSW           46.0          W  ...        30.0       1007.6   \n",
       "3          NE           24.0         SE  ...        16.0       1017.6   \n",
       "4           W           41.0        ENE  ...        33.0       1010.8   \n",
       "\n",
       "   Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  RainTomorrow  \\\n",
       "0       1007.1       8.0       NaN     16.9     21.8         No            No   \n",
       "1       1007.8       NaN       NaN     17.2     24.3         No            No   \n",
       "2       1008.7       NaN       2.0     21.0     23.2         No            No   \n",
       "3       1012.8       NaN       NaN     18.1     26.5         No            No   \n",
       "4       1006.0       7.0       8.0     17.8     29.7         No            No   \n",
       "\n",
       "   RainfallTomorrow  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               1.0  \n",
       "4               0.2  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path= './weatherAUS.csv'\n",
    "df = pd.read_csv(path, usecols=range(1,25))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay registros duplicados\n"
     ]
    }
   ],
   "source": [
    "### Busco duplicados\n",
    "if not df.duplicated().any():\n",
    "  print('No hay registros duplicados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColDropper(BaseEstimator, TransformerMixin):\n",
    "  def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "  def transform(self, X):\n",
    "    return X.drop(['Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocDropper(BaseEstimator, TransformerMixin):\n",
    "  def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "  def transform(self, X):\n",
    "    costa_este = [' Adelaide', 'Canberra', 'Cobar', 'Dartmoor', 'Melbourne', 'MelbourneAirport', 'MountGambier', 'Sydney', 'SydneyAirport' ]\n",
    "    X.loc[X['Location'].isin(costa_este), 'Location'] = 'costa_este'\n",
    "    return X[X['Location'] == 'costa_este']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatFiller(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "      X['WindGustDir'] = X.groupby('Location')['WindGustDir'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "      X['WindDir9am'] = X.groupby('Location')['WindDir9am'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "      X['WindDir3pm'] = X.groupby('Location')['WindDir3pm'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "      return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumFiller(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "      remanining_vnul_columns = X.columns[X.isna().any()].tolist()\n",
    "      for col in remanining_vnul_columns:\n",
    "        X[col] =  X[col].fillna(X[col].mean())\n",
    "\n",
    "      return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.mdpi.com/2078-2489/13/4/163 Como las variables de la dirección de los vientos pueden tener hasta 16 direcciones diferentes, para convertirlos a variables numéricas, se tiene encuenta una distribución circular. Por eso, cada una de las variables se dividió en dos: Una con el seno y otra con el coseno del angulo\n",
    "class CoordRecat(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        coord = {\n",
    "            'N': 0, 'NNE': 22.5, 'NE': 45, 'ENE': 67.5,\n",
    "            'E': 90, 'ESE': 112.5, 'SE': 135, 'SSE': 157.5,\n",
    "            'S': 180, 'SSW': 202.5, 'SW': 225, 'WSW': 247.5,\n",
    "            'W': 270, 'WNW': 292.5, 'NW': 315, 'NNW': 337.5,\n",
    "        }\n",
    "\n",
    "        # Aplicar la recategorización\n",
    "        for col in ['WindGustDir', 'WindDir9am', 'WindDir3pm']:\n",
    "            X[col] = X[col].map(coord)\n",
    "            X[f'{col}_rad'] = np.deg2rad(X[col])\n",
    "            X[f'{col}_sin'] = np.sin(X[f'{col}_rad']).round(5)\n",
    "            X[f'{col}_cos'] = np.cos(X[f'{col}_rad']).round(5)\n",
    "\n",
    "        # Eliminar columnas originales y columnas radianes\n",
    "        columns_to_drop = [f'{col}_rad' for col in ['WindGustDir', 'WindDir9am', 'WindDir3pm']] + ['WindGustDir', 'WindDir9am', 'WindDir3pm']\n",
    "        X = X.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "      dummies = pd.get_dummies(X['Location'], dtype=int)\n",
    "      X = pd.concat([X, dummies], axis=1)\n",
    "      X.drop('Location', axis=1, inplace=True)\n",
    "\n",
    "      return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetIndex(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoolYNDropperEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "      X.dropna(subset=['RainToday'], inplace=True)\n",
    "      X['RainTomorrow'] = X['RainTomorrow'].map({'No': 0, 'Yes': 1}).astype(float)\n",
    "      X['RainToday'] = X['RainToday'].map({'No': 0, 'Yes': 1}).astype(float)\n",
    "\n",
    "      return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standarizer(BaseEstimator, TransformerMixin):\n",
    "  def fit(self, X, y=None):\n",
    "      return self\n",
    "  def transform(self, X):\n",
    "    # Exclusión de variables booleanas y RainfallTmorrow porque no serán estandarizaradas\n",
    "    exc_c = ['RainToday', 'RainTomorrow']#, ,'Canberra','Cobar', 'Dartmoor', 'Melbourne', 'MelbourneAirport', 'MountGambier', 'Sydney', 'SydneyAirport']\n",
    "\n",
    "    # Estandarización\n",
    "    df_sub = X[[col for col in X.columns if col not in exc_c]]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df_sub)\n",
    "\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=df_sub.columns)\n",
    "    for col in exc_c:\n",
    "      X_scaled[f'{col}'] = X[col]\n",
    "\n",
    "    # Nuevo DataFrame estandarizado con los nombres de las columnas originales\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutliersTreater(BaseEstimator, TransformerMixin):\n",
    "  def fit(self, X, y=None):\n",
    "      return self\n",
    "  def transform(self, X):\n",
    "    cols_with_ouliers=['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine',\n",
    "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
    "       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm',\n",
    "       'Temp9am', 'Temp3pm']\n",
    "\n",
    "    for col in cols_with_ouliers:\n",
    "      IQR=X[col].quantile(0.75)-X[col].quantile(0.25)\n",
    "      lower_bridge=X[col].quantile(0.25)-(IQR*1.5)\n",
    "      upper_bridge=X[col].quantile(0.75)+(IQR*1.5)\n",
    "\n",
    "      X.loc[X[col]>=round(upper_bridge,2),col]=round(upper_bridge,2)\n",
    "      X.loc[X[col]<=round(lower_bridge,2),col]=round(lower_bridge,2)\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLValDropper(BaseEstimator, TransformerMixin):\n",
    "  def fit (self, X, y=None):\n",
    "    return self\n",
    "  def transform(self, X):\n",
    "    X.dropna(subset=['RainToday', 'RainTomorrow'], inplace=True)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Pipeline([\n",
    "     ('drop_null_val_rl', RLValDropper()),\n",
    "     ('drop_not_needed_features', ColDropper()),\n",
    "     ('drop_nor_needed_locations',LocDropper()),\n",
    "     ('yes_no_dropper_encoder', BoolYNDropperEncoder()),\n",
    "     ('fill_null_cat', CatFiller()),\n",
    "     ('fill_num_cat', NumFiller()),\n",
    "     ('encode_loc', LocEncoder()),\n",
    "     ('encode_wind_dir', CoordRecat()),\n",
    "     ('reset_index',ResetIndex()),\n",
    "     ('treat_outliers',OutliersTreater()),\n",
    "     ('standariza_values', Standarizer())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((116329, 23), (29083, 23), (116329, 1), (29083, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separación de variables explicativas y variables objetivo\n",
    "X = df.drop(['RainfallTomorrow'], axis=1).copy()\n",
    "y = df[['RainfallTomorrow']].copy()\n",
    "\n",
    "# Spliteo mi dataset en train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo un Dataframe de TRAIN\n",
    "df_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "df_train['RainfallTomorrow'] = y['RainfallTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo un Dataframe de TEST\n",
    "df_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "df_test['RainfallTomorrow'] = y['RainfallTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preproceso mi df de test y mi df de train\n",
    "df_train = preprocessor.fit_transform(df_train)\n",
    "df_test = preprocessor.fit_transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regresion = df_train.iloc[:, :-1]\n",
    "y_train_regresion = df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_regresion = df_test.iloc[:, :-1]\n",
    "y_test_regresion = df_test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal para regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstudy = optuna.create_study(direction=\\'minimize\\')  # MINIMIZAR PERDIDA\\nstudy.optimize(objective_reg, n_trials=100)\\n\\nbest_params = study.best_params\\nprint(\"Best parameters:\", best_params)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective_reg(trial):\n",
    "    # Crear el modelo\n",
    "    model = Sequential()\n",
    "\n",
    "    # Definir hiperparámetros a optimizar\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "    model.add(Dense(10, activation='relu', input_shape=(X_train_regresion.shape[1],)))\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        num_units = trial.suggest_int(f'n_units_layer_{i}', 4, 128)\n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1))  # Capa de salida para regresión lineal\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train_regresion, y_train_regresion, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train_regresion, y_train_regresion, validation_data=(X_valid, y_valid), epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    score = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "    return score\n",
    "\n",
    "\n",
    "'''\n",
    "study = optuna.create_study(direction='minimize')  # MINIMIZAR PERDIDA\n",
    "study.optimize(objective_reg, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best parameters:\", best_params)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_reg = Sequential([\n",
    "        Dense(124, activation='relu', input_shape=(X_train_regresion.shape[1],)),\n",
    "        Dropout(0.05),\n",
    "        Dense(120, activation='relu'),\n",
    "        Dropout(0.05),\n",
    "        Dense(60, activation='relu'),\n",
    "        Dropout(0.05),\n",
    "        Dense(24, activation='relu'),\n",
    "        Dropout(0.05),\n",
    "        Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model_reg.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step\n",
      "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step\n"
     ]
    }
   ],
   "source": [
    "train_scores = model_reg.evaluate(X_train_regresion, y_train_regresion, verbose=0)\n",
    "valid_scores = model_reg.evaluate(X_test_regresion, y_test_regresion, verbose=0)\n",
    "\n",
    "\n",
    "train_r2 = r2_score(y_train_regresion, model_reg.predict(X_train_regresion))\n",
    "valid_r2 = r2_score(y_test_regresion, model_reg.predict(X_test_regresion))\n",
    "\n",
    "train_mse = mean_squared_error(y_train_regresion, model_reg.predict(X_train_regresion))\n",
    "valid_mse = mean_squared_error(y_test_regresion, model_reg.predict(X_test_regresion))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Train R^2: -0.04\n",
      "Train MSE: 0.19\n",
      "Test\n",
      "Test R^2: -0.04\n",
      "Test MSE: 0.19\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "print(f\"Train R^2: {train_r2:.2f}\")\n",
    "print(f\"Train MSE: {train_mse:.2f}\")\n",
    "print(\"Test\")\n",
    "print(f\"Test R^2: {valid_r2:.2f}\")\n",
    "print(f\"Test MSE: {valid_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_reg(trial: Trial):\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Define hyperparameters to optimize\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "    num_units_input = trial.suggest_int('n_units_input', 4, 128)\n",
    "    model.add(Dense(num_units_input, activation='relu', input_shape=(X_train_regresion.shape[1],)))\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        num_units = trial.suggest_int(f'n_units_layer_{i}', 4, 128)\n",
    "        model.add(Dense(num_units, activation='relu'))\n",
    "        dropout_rate = trial.suggest_float(f'dropout_rate_layer_{i}', 0.0, 0.5)\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))  # Output layer for regression\n",
    "\n",
    "    # Compile the model\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train_regresion, y_train_regresion, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-05 19:01:00,320] A new study created in memory with name: no-name-dbd13566-7bb3-4710-90ce-ba402e71af25\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2024-06-05 19:01:02,784] Trial 0 finished with value: 0.1143878921866417 and parameters: {'num_layers': 1, 'n_units_input': 54, 'n_units_layer_0': 39, 'dropout_rate_layer_0': 0.22806121937111695, 'learning_rate': 3.0956621766653625e-05}. Best is trial 0 with value: 0.1143878921866417.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2024-06-05 19:01:06,976] Trial 1 finished with value: 0.18453378975391388 and parameters: {'num_layers': 5, 'n_units_input': 104, 'n_units_layer_0': 22, 'dropout_rate_layer_0': 0.20298991696697877, 'n_units_layer_1': 52, 'dropout_rate_layer_1': 0.0030241131049274506, 'n_units_layer_2': 127, 'dropout_rate_layer_2': 0.3954446256226377, 'n_units_layer_3': 107, 'dropout_rate_layer_3': 0.46163703719798427, 'n_units_layer_4': 22, 'dropout_rate_layer_4': 0.28280158011560125, 'learning_rate': 0.025137477535632963}. Best is trial 0 with value: 0.1143878921866417.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2024-06-05 19:01:10,505] Trial 2 finished with value: 0.0390353724360466 and parameters: {'num_layers': 3, 'n_units_input': 96, 'n_units_layer_0': 97, 'dropout_rate_layer_0': 0.32700446286252755, 'n_units_layer_1': 26, 'dropout_rate_layer_1': 0.4772190684557889, 'n_units_layer_2': 22, 'dropout_rate_layer_2': 0.41005399104774637, 'learning_rate': 0.007541510647283381}. Best is trial 2 with value: 0.0390353724360466.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2024-06-05 19:01:13,731] Trial 3 finished with value: 0.09437477588653564 and parameters: {'num_layers': 2, 'n_units_input': 75, 'n_units_layer_0': 52, 'dropout_rate_layer_0': 0.49073418416471853, 'n_units_layer_1': 110, 'dropout_rate_layer_1': 0.17845551638770585, 'learning_rate': 7.470759981968885e-05}. Best is trial 2 with value: 0.0390353724360466.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2024-06-05 19:01:16,351] Trial 4 finished with value: 0.12225081771612167 and parameters: {'num_layers': 1, 'n_units_input': 54, 'n_units_layer_0': 70, 'dropout_rate_layer_0': 0.21912940401163344, 'learning_rate': 1.1019970440846765e-05}. Best is trial 2 with value: 0.0390353724360466.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2024-06-05 19:01:20,423] Trial 5 finished with value: 0.0618688240647316 and parameters: {'num_layers': 4, 'n_units_input': 103, 'n_units_layer_0': 87, 'dropout_rate_layer_0': 0.3498749656783939, 'n_units_layer_1': 41, 'dropout_rate_layer_1': 0.1988261859684397, 'n_units_layer_2': 40, 'dropout_rate_layer_2': 0.4335733575299335, 'n_units_layer_3': 91, 'dropout_rate_layer_3': 0.024717365852911843, 'learning_rate': 0.01157625273500887}. Best is trial 2 with value: 0.0390353724360466.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2024-06-05 19:01:23,970] Trial 6 finished with value: 0.04209837317466736 and parameters: {'num_layers': 4, 'n_units_input': 117, 'n_units_layer_0': 12, 'dropout_rate_layer_0': 0.39520463422907826, 'n_units_layer_1': 37, 'dropout_rate_layer_1': 0.2856253078505799, 'n_units_layer_2': 96, 'dropout_rate_layer_2': 0.3162288582489201, 'n_units_layer_3': 16, 'dropout_rate_layer_3': 0.43454479547066416, 'learning_rate': 0.0006527345396930666}. Best is trial 2 with value: 0.0390353724360466.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2024-06-05 19:01:26,781] Trial 7 finished with value: 0.006619363557547331 and parameters: {'num_layers': 2, 'n_units_input': 72, 'n_units_layer_0': 36, 'dropout_rate_layer_0': 0.3371050510392292, 'n_units_layer_1': 59, 'dropout_rate_layer_1': 0.07695653787599349, 'learning_rate': 0.003720320233710464}. Best is trial 7 with value: 0.006619363557547331.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2024-06-05 19:01:30,717] Trial 8 finished with value: 0.008269037120044231 and parameters: {'num_layers': 3, 'n_units_input': 103, 'n_units_layer_0': 74, 'dropout_rate_layer_0': 0.4402624177955778, 'n_units_layer_1': 128, 'dropout_rate_layer_1': 0.4122428247324776, 'n_units_layer_2': 115, 'dropout_rate_layer_2': 0.15316323619662325, 'learning_rate': 0.001233996666848874}. Best is trial 7 with value: 0.006619363557547331.\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2024-06-05 19:01:33,360] Trial 9 finished with value: 0.0069259703159332275 and parameters: {'num_layers': 1, 'n_units_input': 34, 'n_units_layer_0': 88, 'dropout_rate_layer_0': 0.035851757590200706, 'learning_rate': 0.025782824721517064}. Best is trial 7 with value: 0.006619363557547331.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run the Optuna optimization with a limited number of trials for a mockup run\n",
    "study = optuna.create_study(direction='minimize')  # Minimize the loss\n",
    "study.optimize(objective_reg, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'num_layers': 2, 'n_units_input': 72, 'n_units_layer_0': 36, 'dropout_rate_layer_0': 0.3371050510392292, 'n_units_layer_1': 59, 'dropout_rate_layer_1': 0.07695653787599349, 'learning_rate': 0.003720320233710464}\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Train the best model on the entire training data\n",
    "best_model = Sequential()\n",
    "best_model.add(Dense(best_params['n_units_input'], activation='relu', input_shape=(X_train_regresion.shape[1],)))\n",
    "\n",
    "\n",
    "for i in range(best_params['num_layers']):\n",
    "    best_model.add(Dense(best_params[f'n_units_layer_{i}'], activation='relu'))\n",
    "    best_model.add(Dropout(best_params[f'dropout_rate_layer_{i}']))\n",
    "    \n",
    "best_model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the best model\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2509e673bc0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the best model\n",
    "best_model.fit(X_train_regresion, y_train_regresion, epochs=10, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step\n",
      "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "train_scores = best_model.evaluate(X_train_regresion, y_train_regresion, verbose=0)\n",
    "valid_scores = best_model.evaluate(X_test_regresion, y_test_regresion, verbose=0)\n",
    "\n",
    "train_r2 = r2_score(y_train_regresion, best_model.predict(X_train_regresion))\n",
    "valid_r2 = r2_score(y_test_regresion, best_model.predict(X_test_regresion))\n",
    "\n",
    "train_mse = mean_squared_error(y_train_regresion, best_model.predict(X_train_regresion))\n",
    "valid_mse = mean_squared_error(y_test_regresion, best_model.predict(X_test_regresion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2: 0.9842460619276749, Validation R2: 0.9799315781640838\n",
      "Train MSE: 0.002851142940001087, Validation MSE: 0.0035671638252921167\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train R2: {train_r2}, Validation R2: {valid_r2}\")\n",
    "print(f\"Train MSE: {train_mse}, Validation MSE: {valid_mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
